# =================================================================================
# Package Import
# =================================================================================

import os
import cx_Oracle
import pandas as pd
import numpy as np
import math
import csv
import datetime as dt

# visualization
# %matplotlib inline only for notebook tools
import seaborn as sns
import matplotlib.pyplot as plt

# =================================================================================
# Function Defination
# =================================================================================

def exp_type_plot(data, x, y, exp_type, swarm=False):
    exp_type_lt = [exp_type]
    temp_df = data[data.EXP_TYPE.isin(exp_type_lt)]
    height = data[y].nunique()
    plt.figure(figsize=[12, height])  # current Axes
    ax = sns.boxplot(x=x, y=y, data=temp_df)
    sns.swarmplot(x=x, y=y, data=temp_df, color=".3") if swarm == True else None
    ax.set_title(exp_type + ' vs ' + y)


def exp_type_plot_bv(data, x, y, exp_type, swarm=False):
    exp_type_lt = [exp_type]
    temp_df = data[data.EXP_TYPE.isin(exp_type_lt)]
    height = data[y].nunique() * 3

    fig, (axis1, axis2) = plt.subplots(2, 1, figsize=(12, height))

    sns.boxplot(x=x, y=y, data=temp_df, ax=axis1)
    sns.swarmplot(x=x, y=y, data=temp_df, color=".3", ax=axis1) if swarm == True else None
    axis1.set_title(exp_type + ' vs ' + y)

    sns.violinplot(x=x, y=y, data=temp_df, split=True, ax=axis2)

# =================================================================================
# Set Params & Env Var
# =================================================================================

# os.environ['NLS_LANG'] = 'SIMPLIFIED CHINESE_CHINA.UTF8'
# os.environ['NLS_LANG'] = 'SIMPLIFIED CHINESE_SINGAPORE.ZHT16GBK'
# os.environ['NLS_LANG'] = 'AMERICAN_AMERICA.WE8MSWIN1252'
os.environ['NLS_LANG'] = 'ENGLISH_UNITED KINGDOM.AL32UTF8'

# sns.set_style('whitegrid',{'font.sans-serif':['simhei','Arial']})
sns.set_style('whitegrid',{'font.sans-serif':['Arial','Arial']})

# 用来正常显示中文标签
plt.rcParams['font.sans-serif']=['SimHei']
# 用来正常显示负号
plt.rcParams['axes.unicode_minus']=False
plt.rcParams['font.size'] = 12


# =================================================================================
#
# Data extraction from DB
#
# =================================================================================

# Oracle client environment variable
os.putenv('ORACLE_HOME', "C:\\app\oracle\\client11g\\product\\11.2.0\\client_2")
os.putenv('LD_LIBRARY_PATH', "C:\\app\\oracle\\client11g\\product\\11.2.0\\client_2\\lib")

# connect security information

user_id = 'APAC_FIN_COMP_MART'
pass_wd = 'not_apac_fin_comp'

# user_id = 'APAC_FIN_COMP_CORE'
# pass_wd = 'not_apac_fin_comp'

# Workflow data which is in another schema
# user_id = 'APAC_CONCUR_CORE'
# pass_wd = 'not_apac_concur'

# GODW server tns
dsn_tns = cx_Oracle.makedsn('exak-scan.kau.roche.com', 15210, service_name='OTHER_GODWP.KAU.ROCHE.COM')

connection = cx_Oracle.connect(user_id, pass_wd, dsn_tns)

'''
Schema	PROD_APAC_FIN_COMP_MART
Usage for	Yellow flag
Table Name	                Description
DM_F_YF_CM_SRC	            yellow flag fact table
DM_F_CORP_CRDT_CRD_MSTR	    Credit card details
DM_F_RG_MT_BLACK_LIST_YF	Black list venue
'''

# read metadata of oracle
# SQL = "select tablespace_name, table_name from user_tables"
# cursor = connection.cursor()
# cursor.execute(SQL)
# for row in cursor:
#     print(row)
# cursor.close()

"""
Yellow flag table contain 626811 records for 1753
In the table, the latest report date is 2017-5-29
"""

SQL = "select count(1) from DM_F_YF_CM_SRC where COMPANY_CODE = '1753' FETCH FIRST 50 ROWS ONLY"
df_ora = pd.read_sql(SQL, con=connection)
print(df_ora)

# SQL = "select distinct(report_date) from DM_F_YF_CM_SRC where COMPANY_CODE = '1753' order by REPORT_DATE"
# cursor = connection.cursor()
# cursor.execute(SQL)
# result = cursor.fetchall()
# cursor.close()
# print(result)

SQL = "select distinct(report_date) from DM_F_YF_CM_SRC where COMPANY_CODE = '1753' order by REPORT_DATE"
df_ora = pd.read_sql(SQL, con=connection)
print(df_ora)

# Column information of the table
"""
Column_Names				Column_Description
DWH_ID				        Surrogate key generated by ETL
EXP_TYPE				    Expense types - ex :- Taxi , meals, Hotels, Dinnererc
EMPLOYEE_NAME				Claimant Name
EMPLOYEE_ID				    Claimant ID
EMPLOYEE_COUNTRY_CODE		Claimant company code - roche centers in different country - ex:- CN for china , HK for hong kong , IN for india etc..
RPT_NAME				    Claim Name as per oncur
COMPANY_NAME				roche center names , Multiple company names can belong under single country code as there can be more than one center in one country
RPT_COUNTRY_CODE			same as employee country code
COMPANY_CODE				codes for company name
RPT_CC_CODE		    		NA
RPT_LEGACY_KEY				Claim ID
RPT_ID				        Claim key (equivalent to claim ID)
FIRST_SUBMITTED_DATE		The date when claim is first submitted
LAST_SUBMITTED_DATE			The date on which the claim is re-submitted after rejection
IS_SENT_BACK				flag to check weather a claim is sent back to employee or not
SENT_BACK_CODE				sent back reason code
SENT_BACK_TEXT				sent back reason
APPROVAL_STATUS				status of claim approval
PAYMENT_DATE				date on which payment made for the claim
TRANSACTION_NO				line items under each claim
ORG_5_NAME				    NA
ORG_5_CODE				    NA
PEER_ID				        Peer ID
T_DATE				        Date on which transaction happens on a line item , ex :- Date of dinner or breakfast etc..
PAYMENT_TYPE				which payment method is used , Credit card of Cash.
VENDOR				        vendor
LOCATION				    Location where transaction took place
T_CURRENCY				    Currency on which transaction happened
T_AMT				        Amount of transaction
RATE				        Rate of conversion for transaction currency and reimbursement currency
REIMBUR_CURRENCY			Currency on which payment made to the claimant
REIMBUR_AMT				    Amount of reimbursement paid to the claimant
CLAIMED_AMT				    Total amount claimed for a claim(Sum of all transaction amount in a claim)
APPROVED_AMT				The approved amount for each line item
INVOICE_NUMBER				invoice number for line items
CHRIS_ID				    HR id
REPORT_DATE				    Date on which report is generated for the compliance team
PERSONAL				    flag to mark personal expenses
REROUTE_CLAIM_FLAG			NA
"""

# import 1753 data to dataframe
SQL = """
Select 
    EXP.EXP_TYPE, EXP.EMPLOYEE_NAME, EXP.EMPLOYEE_COUNTRY_CODE, EXP.RPT_NAME, EXP.COMPANY_NAME, 
    EXP.RPT_COUNTRY_CODE, EXP.COMPANY_CODE, EXP.RPT_CC_CODE, EXP.RPT_LEGACY_KEY, 
    EXP.FIRST_SUBMITTED_DATE, EXP.LAST_SUBMITTED_DATE, EXP.IS_SENT_BACK, EXP.PURPOSE,
    EXP.SENT_BACK_CODE, EXP.SENT_BACK_TEXT, EXP.APPROVAL_STATUS, EXP.PAYMENT_DATE, 
    EXP.TRANSACTION_NO, EXP.ORG_5_NAME, EXP.ORG_5_CODE, EXP.T_DATE, EXP.PAYMENT_TYPE, 
    EXP.VENDOR, EXP.LOCATION, EXP.T_CURRENCY, EXP.T_AMT, EXP.RATE, EXP.REIMBUR_CURRENCY,
    EXP.REIMBUR_AMT, EXP.CLAIMED_AMT, EXP.APPROVED_AMT, EXP.REPORT_DATE, 
    EMP.E_NAME, EMP.AD, EMP.EMPLOYEE_ID, EMP.SEX, EMP.LOCAL_NAME, EMP.PIN_YIN, 
    EMP.M_POSITION, EMP.EMPLOYMENT_DATE, EMP.IT_DEPARTMENT, EMP.COST_CENTER, 
    EMP.CITY, EMP.BRANCH, EMP.COUNTRY_CODE, EMP.DIVISION,
    INT_EMP.USERID, INT_EMP.LASTNAME, INT_EMP.FIRSTNAME, INT_EMP.PERSISTANTPERSID, 
    INT_EMP.LOCALEMPLOYEEID, INT_EMP.EMPLOYEECATEROGRY, INT_EMP.LOCATION as EMP_LOCATION, 
    INT_EMP.COUNTRYTXT, INT_EMP.AD_DOMAIN, INT_EMP.AD_ADMINUNIT, INT_EMP.LM_USERID, 
    INT_EMP.LM_LASTNAME, INT_EMP.LM_FIRSTNAME, INT_EMP.LM_PERSISTANTPERSID, 
    INT_EMP.LM_LOCALEMPLOYEEID, INT_EMP.LM_GLOBALCOSTCENTERCD
  from APAC_CONCUR_CORE.co_expense_entry EXP, 
        APAC_FIN_COMP_MART.dm_d_employee EMP,
        APAC_CONCUR_CORE.co_int_user INT_EMP
  where EXP.EMPLOYEE_ID = INT_EMP.persistantpersid and INT_EMP.USERID = EMP.AD
    and EXP.COMPANY_CODE = '1753'
    and EXP_TYPE is not null and EXP_TYPE <> 'Undefined' 
    and T_DATE >= To_Date ('2017-01-01', 'YYYY-MM-DD')
    and EXP.REIMBUR_AMT > 0 
--    and EMP.DIVISION in ('BU1', 'BUO1')
    and EMP.DIVISION in ('BU AnS')
"""

co_expense_entry_df = pd.read_sql(SQL, con=connection)
co_expense_entry_df.head()

# Close the oracle db connection
connection.close()


# =================================================================================
# Save data to local for easy access.
# =================================================================================

# Write Data
# writer = pd.ExcelWriter('.\Data\co_expense_entry_1753_2017.xlsx')
writer = pd.ExcelWriter('.\Data\co_expense_entry_1753_2017_BU_ANS.xlsx')
co_expense_entry_df.to_excel(writer,'Sheet1')
writer.save()
writer.close()


# =================================================================================
# Read data from local files
# =================================================================================

# location_file = './Data/co_expense_entry_1753_2017_BU1_BUO1.xlsx'
location_file = './Data/co_expense_entry_1753_2017_BU_ANS.xlsx'
co_expense_entry_df = pd.read_excel(location_file, sheetname="Sheet1")

# location master file
location_file = './Data/city.xls'
location_df = pd.read_excel(location_file, sheetname="city")
location_df = location_df[['CITY_NAME_ST', 'CITY_NAME_EN', 'CITY_TIER']]

# # Network drive somewhere
# filename = ".\YF_CM_USER_DF.csv"
# FILE = open(filename, "w")
# output = csv.writer(FILE, dialect='excel')
# cursor = connection.cursor()
# cursor.execute(SQL)
# for row in cursor:
#     output.writerow(row)
# cursor.close()
# connection.close()
# FILE.close()

"""
==================================================================================
Data Transforming

## Row Data:

* DM_F_YF_CM_SRC_DF
    * table DM_F_YF_CM_SRC, the yellow flag table
* co_expense_entry_df
    * table co_expense_entry, the concur claim entry table.
* location_df
    * Excel file for location master data, like chinese & english name

## To be build:

* yf_df
    * based on DM_F_YF_CM_SRC_DF join with master data: location. 
* co_df
    * based on co_expense_entry_df join with master data: location. 
==================================================================================
"""

# Translate CHINESE to English for CITY

co_df = co_expense_entry_df

co_df = co_df.join(location_df.set_index('CITY_NAME_ST'), on='LOCATION')

# co_df[['LOCATION', 'CITY_NAME_EN']].fillna(0).apply(lambda x: x['CITY_NAME_EN']==0 , axis=1)

co_df['LOCATION_EN'] = co_df[['LOCATION', 'CITY_NAME_EN']].fillna(0).apply(lambda x:
     str(x['LOCATION']).upper() if x['CITY_NAME_EN'] == 0 else x["CITY_NAME_EN"], axis=1)

# co_df_index = co_df.set_index(['USERID', 'T_DATE'])

co_df.head()

# DM_F_YF_CM_SRC_DF = DM_F_YF_CM_SRC_DF.drop(['LOCATOIN_EN'], axis=1)

"""
==================================================================================
Data Understanding
==================================================================================
"""

co_df[['EXP_TYPE' ,'DIVISION',  'REIMBUR_AMT']].groupby(["EXP_TYPE", 'DIVISION']).describe()

exp_type_plot(exp_type='Lunch', x='REIMBUR_AMT', y='DIVISION', data=co_df)

co_df.columns

"""
['EXP_TYPE', 'EMPLOYEE_NAME', 'EMPLOYEE_COUNTRY_CODE', 'RPT_NAME',
       'COMPANY_NAME', 'RPT_COUNTRY_CODE', 'COMPANY_CODE', 'RPT_CC_CODE',
       'RPT_LEGACY_KEY', 'FIRST_SUBMITTED_DATE', 'LAST_SUBMITTED_DATE',
       'IS_SENT_BACK', 'PURPOSE', 'SENT_BACK_CODE', 'SENT_BACK_TEXT',
       'APPROVAL_STATUS', 'PAYMENT_DATE', 'TRANSACTION_NO', 'ORG_5_NAME',
       'ORG_5_CODE', 'T_DATE', 'PAYMENT_TYPE', 'VENDOR', 'LOCATION',
       'T_CURRENCY', 'T_AMT', 'RATE', 'REIMBUR_CURRENCY', 'REIMBUR_AMT',
       'CLAIMED_AMT', 'APPROVED_AMT', 'REPORT_DATE', 'E_NAME', 'AD',
       'EMPLOYEE_ID', 'SEX', 'LOCAL_NAME', 'PIN_YIN', 'M_POSITION',
       'EMPLOYMENT_DATE', 'IT_DEPARTMENT', 'COST_CENTER', 'CITY', 'BRANCH',
       'COUNTRY_CODE', 'DIVISION', 'USERID', 'LASTNAME', 'FIRSTNAME',
       'PERSISTANTPERSID', 'LOCALEMPLOYEEID', 'EMPLOYEECATEROGRY',
       'EMP_LOCATION', 'COUNTRYTXT', 'AD_DOMAIN', 'AD_ADMINUNIT', 'LM_USERID',
       'LM_LASTNAME', 'LM_FIRSTNAME', 'LM_PERSISTANTPERSID',
       'LM_LOCALEMPLOYEEID', 'LM_GLOBALCOSTCENTERCD', 'CITY_NAME_EN',
       'CITY_TIER', 'LOCATION_EN']
"""

"""
==================================================================================
# Create Dataframe with key / index = userid and date
==================================================================================
"""

User_Date_Columns = ['User','Date',
                     'Taxi_Cnt', 'Taxi_Loc_Cnt',
                     'Train_Cnt', 'Train_Loc_Cnt',
                     'Pub_Tpt_Cnt', 'Pub_Tpt_Loc_Cnt',
                     'HCPs_Meal_Cnt', 'HCPs_Meal_Loc_Cnt',
                     'Congress_Cnt', 'Congress_Loc_Cnt',
                     'Hotel_Cnt', 'Hotel_Loc_Cnt',
                     'Lunch_Cnt', 'Lunch_Loc_Cnt',
                     'Dinner_Cnt', 'Dinner_Loc_Cnt'
                     ]


# get user and date list as key
User_Date_df = pd.DataFrame(co_df[['USERID', 'T_DATE', 'REIMBUR_AMT']][co_df.EMP_LOCATION=='TAIYUAN (TAY)'].\
                                           groupby(['USERID', 'T_DATE'], as_index=True).count().index.tolist(),\
                                           columns=['User','Date'])

print( 'User_Date_df:', User_Date_df.columns.size, User_Date_df.iloc[:,0].size)

# co_df[['USERID', 'T_DATE', 'REIMBUR_AMT']].head(100).groupby(['USERID', 'T_DATE'], as_index=False).groups.keys()

User_Date_df.head()

User_Date_Exp_df = pd.DataFrame(columns=User_Date_Columns)
User_Date_Exp_df = User_Date_Exp_df.append(User_Date_df)  # clear before append
User_Date_Exp_df = User_Date_Exp_df[User_Date_Columns].fillna(0)

print( 'User_Date_Exp_df:', User_Date_Exp_df.columns.size, User_Date_Exp_df.iloc[:,0].size)

co_df[(co_df.USERID == 'BAIL')].head()

i = 0
for index, User_Date_Exp_row in User_Date_Exp_df.iterrows():

    co_user_date_df = co_df[['USERID', 'T_DATE', 'EXP_TYPE', 'REIMBUR_AMT', 'LOCATION_EN']] \
                            [(co_df.USERID == User_Date_Exp_row['User'])& \
                            (co_df.T_DATE == User_Date_Exp_row['Date'])]

    HCPs_Meal_Cnt = co_user_date_df[(co_user_date_df.EXP_TYPE == 'Business Meal with HCPs')]['REIMBUR_AMT'].count()

    HCPs_Meal_Loc_Cnt = len(co_user_date_df[(co_user_date_df.EXP_TYPE == 'Business Meal with HCPs')]['LOCATION_EN'].unique())

    User_Date_Exp_df.loc[index, 'HCPs_Meal_Cnt'] = HCPs_Meal_Cnt
    User_Date_Exp_df.loc[index, 'HCPs_Meal_Loc_Cnt'] = HCPs_Meal_Loc_Cnt

    Taxi_Cnt = co_user_date_df[(co_user_date_df.EXP_TYPE == 'Taxi')]['REIMBUR_AMT'].count()

    Taxi_Loc_Cnt = len(co_user_date_df[(co_user_date_df.EXP_TYPE == 'Taxi')]['LOCATION_EN'].unique())

    User_Date_Exp_df.loc[index, 'Taxi_Cnt'] = Taxi_Cnt
    User_Date_Exp_df.loc[index, 'Taxi_Loc_Cnt'] = Taxi_Loc_Cnt

    Hotel_Cnt = co_user_date_df[(co_user_date_df.EXP_TYPE == 'Hotel')]['REIMBUR_AMT'].count()

    Hotel_Loc_Cnt = len(co_user_date_df[(co_user_date_df.EXP_TYPE == 'Hotel')]['LOCATION_EN'].unique())

    User_Date_Exp_df.loc[index, 'Hotel_Cnt'] = Hotel_Cnt
    User_Date_Exp_df.loc[index, 'Hotel_Loc_Cnt'] = Hotel_Loc_Cnt

    Train_Cnt = co_user_date_df[(co_user_date_df.EXP_TYPE == 'Train')]['REIMBUR_AMT'].count()
    Train_Loc_Cnt = len(co_user_date_df[(co_user_date_df.EXP_TYPE == 'Train')]['LOCATION_EN'].unique())

    User_Date_Exp_df.loc[index, 'Train_Cnt'] = Train_Cnt
    User_Date_Exp_df.loc[index, 'Train_Loc_Cnt'] = Train_Loc_Cnt

    Lunch_Cnt = co_user_date_df[(co_user_date_df.EXP_TYPE == 'Lunch')]['REIMBUR_AMT'].count()
    Lunch_Loc_Cnt = len(co_user_date_df[(co_user_date_df.EXP_TYPE == 'Lunch')]['LOCATION_EN'].unique())

    User_Date_Exp_df.loc[index, 'Lunch_Cnt'] = Lunch_Cnt
    User_Date_Exp_df.loc[index, 'Lunch_Loc_Cnt'] = Lunch_Loc_Cnt

    Dinner_Cnt = co_user_date_df[(co_user_date_df.EXP_TYPE == 'Dinner')]['REIMBUR_AMT'].count()
    Dinner_Loc_Cnt = len(co_user_date_df[(co_user_date_df.EXP_TYPE == 'Dinner')]['LOCATION_EN'].unique())

    User_Date_Exp_df.loc[index, 'Dinner_Cnt'] = Dinner_Cnt
    User_Date_Exp_df.loc[index, 'Dinner_Loc_Cnt'] = Dinner_Loc_Cnt

    Pub_Tpt_Cnt = co_user_date_df[(co_user_date_df.EXP_TYPE == 'Public Transport')]['REIMBUR_AMT'].count()
    Pub_Tpt_Loc_Cnt = len(co_user_date_df[(co_user_date_df.EXP_TYPE == 'Public Transport')]['LOCATION_EN'].unique())

    User_Date_Exp_df.loc[index, 'Pub_Tpt_Cnt'] = Pub_Tpt_Cnt
    User_Date_Exp_df.loc[index, 'Pub_Tpt_Loc_Cnt'] = Pub_Tpt_Loc_Cnt

    i = i + 1
    if i % 100 == 0: print(i)

User_Date_Exp_df = User_Date_Exp_df[User_Date_Columns]


# Test Code

len(co_df[(co_df.USERID == 'ZHANGL84')&(co_df.T_DATE == dt.date(2017,4,20))&
      (co_df.EXP_TYPE == 'Taxi')]['LOCATION_EN'].unique())

s = pd.Series(['FLAP....1310', 'MAEIAA..1718', 'MACEAA8B2701'])
s.str.extract('(\d{4,4}$)', expand=False)
s.str.extract('(^\w{1,8})', expand=False)